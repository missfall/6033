# Rec 16: Logging
### Tues Apr 11, 2017
Log-Structured File System (LFS)

--------------------------

## ---- Class Notes ------

Good Recitation Grade:
- Engineering Group Meeting
    - purpose: fight for your group in the hierarchy.
- Aggressive Question.  

- LFS - Garbage Collection - cleans cold segments before hot segments,
    - doesn't pay attention to which ones have more dead blocks.

Microsoft's first enemy was Lotus.
- Apple came back from death because Microsoft lent them money. They did this even though they were an enemy just to keep the competition alive. (same thing happens in english soccer league)

## ----- Logging ------
- BEGIN
- END
- COMMIT
- CHECKPOINT
-



#### ------- L-F-S -------
Disks are slow.

1. move head to part of disk with i-nodes
2. move head to part of disk with the file data
3. move head to part of disk with i-nodes to change i-node

In the LFS, i-nodes are scattered, not just one place.
- they use an i-node map so that programs know where i-nodes are
    - i-node map is in memory.
- Since it's stored in memory, it needs to be updated in storage periodically.
    - In theory, there could be a fault before the i-node map is synced from memory to storage.
    - To recovery, they do 'log replay' they can trace through the log and see if there are any updates that should be there that aren't.

" Biggest change in the computing environment in my lifetime is that you never have to worry about disk space"

"Amortize the overhead" => Paris travel analogy

Garbage Collection:
- if there is no i-node pointing to the file, its garbage.
- garbage collection is overhead.

Have 2 different checkpoint segments
- put a timestamp at the begining of the write
- put a timestamp at the end of the write

#### weak memory consistency models
Google it.


## ----- Reading Notes --------



- What is one technique that the log-structure filesystem uses to achieve higher performance? (There is more than one technique)
    - The LFS aims to focus on write performance and take advantage of sequential write performance. To do this, they completely eliminate random writes an implement a file system which instead of overwriting data somewhere in storage, copies and re-writes the file sequentially in an open piece of storage.

- How does the log-structured file system implement this technique?
    - When a file needs to be saved, rather than move to a random point inside the file, LFS keeps track of requested writes and buffers them (write-buffering). Then, the LFS can write entire segments sequentially and contiguously in a very efficient manner.

- Why does this technique, along with minimizing seeks, lead to good performance?
    - To really understand the performance gains by this implementation, you need to understand that the storage system is a hard disk, with a moving arm (similar to a move flexible record-player arm) that has to move to different parts of the disk to write to it. This is like going back through a text file with your mouse and changing random characters; you can write text much faster if you leave your fingers on the keys and just write sequentially.  By write-caching and by eliminating random writes, we keep the disk writing sequentially, rather than hopping around the disk space.
