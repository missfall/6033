# Recitation 19: RAFT
### Tuesday April 25th

--------------------------------------------------------------------------------

## ----- Class Notes ------
- Visualization [1](http://thesecretlivesofdata.com/raft/)
- Visualization [2](https://raft.github.io/)

#### Raft!
- Main goal: Be more understandable than the predecessor (Paxos).
- Fundamental Problem: Machines break.
    - Tandem Nonstop Computer Company
    - in 70's people developed technique "replicated state machine"
        - we conceptually view servers as state machines, event driven.
    - replication does not give you reliability, it buys you time before failure.
- Rules for guaranteeing that replicated state machines match:
    1. Operations must be deterministic
    2. All state machines must execute the same sequence of operation
    3. All state machines must state from the same initial state

#### Raft Algorithm
- 



## ------ Reading Notes ------
- RAFT's key design goal was _understandability_
-


- DB nodes can be in 3 states:
    1. Follower
    2. Candidate
    3. Leader (all changes go through the leader)

- Having only 1 distinguished leader (responsible for logs) allows raft to __consensus into 3 relatively isolated sub-problems__:
    1. _Leader Election_
        - 2 timeout settings which control election
            1. Election timeout (time from follower => Candidate) (random)
            2. Heartbeat timeout
    - after the election timeout,  the candidate starts an election term
    - Using a majority election ensures only one leader can be elected per term.
    - Election terms continue until a server stops receiving heartbeats and becomes a candidate
    - tied elections are re-done. The randomization of delays ensures that eventually, there will only be one winner.

    2. _Log Replication_
        - replicate all changes to all nodes
        - sends out "Append Entries" messages
        - logs are sent out every heartbeat to every node
        - once a majority of nodes ack the log, it is commited in the leader and a resp sent to client
    3. _Safety_


- Partitions can occur in the nodes
    - RAFT still works. Only one half the partition will have the majority, the other side queues all its changes.


--------------------------------------------------------------------------------
## ---- Reading Questions ----

* In Raft, what is the leader's function?
    - The leader is responsible for all communications to the client. The leader also is responsible for sending out heartbeats to each of the follower nodes before their timeouts expire, this way if many servers or even the leader become unreachable, a new leader is elected. Additionally, the leader maintains a log and has the responsibility of replicating that log to all the other servers. The leader's log acts as the 'official' copy of the data.
* How does the leader work?
    - Once elected, the leader acts as the entire database from the client's perspective. The leader is the only machine to communicate to the client, and the leader echos his logs and commits to the followers. The leader ensures that during communication to the client, there is always one machine which is the 'real' copy of the data. With leader election, it is ensured that all future leaders in later terms have complete logs from previous terms. This property of leader completeness allows for multiple machines to share being the 'real' or 'go-to' record of data.
* Why does Raft need a leader?
    - Raft needs a leader because (for simplicity) data only flows in one direction. I.e, there is only ever 1 machine at a time which acts as the 'official' or 'real' copy of the data. The rest of the algorithm relies on this fact. In the words of the paper, they need a distinguished leader to have complete responsibility of managing the replicated log. This simplifies the process because the leader doesn't need to ask other servers and it allows raft to break consensus down into 3 relatively isolated sub-problems: leader election,  log replication, and safety.
